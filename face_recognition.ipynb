{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "face_recognition.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abolima/face_recognition/blob/master/face_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "KCmx-fEtktPJ",
        "colab_type": "code",
        "outputId": "417fc834-acbd-4eaf-ff73-61c58df27084",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install cmake"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cmake in /usr/local/lib/python3.6/dist-packages (3.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wpgqRKF4C8C3",
        "colab_type": "code",
        "outputId": "7cc954b7-65b6-4194-d0f8-7bb92936183e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install opencv-python"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (3.4.4.19)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.14.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RXrQtWcCkzGh",
        "colab_type": "code",
        "outputId": "ac64031b-700d-4b90-98bd-5af9dd8ec48f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install dlib"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dlib in /usr/local/lib/python3.6/dist-packages (19.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G1BnsGO6k88R",
        "colab_type": "code",
        "outputId": "c28ffb08-55f5-482b-fd1f-867155e3649d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install face_recognition"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting face_recognition\n",
            "  Downloading https://files.pythonhosted.org/packages/3f/ed/ad9a28042f373d4633fc8b49109b623597d6f193d3bbbef7780a5ee8eef2/face_recognition-1.2.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from face_recognition) (4.0.0)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (19.16.0)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.0)\n",
            "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/3b/4fd8c534f6c0d1b80ce0973d01331525538045084c73c153ee6df20224cf/face_recognition_models-0.3.0.tar.gz (100.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 100.2MB 383kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from face_recognition) (1.14.6)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->face_recognition) (0.46)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Running setup.py bdist_wheel for face-recognition-models ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/d2/99/18/59c6c8f01e39810415c0e63f5bede7d83dfb0ffc039865465f\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face-recognition\n",
            "Successfully installed face-recognition-1.2.3 face-recognition-models-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jTb2pp7KlEQM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import face_recognition\n",
        "import cv2 as cv2 #OpenCV\n",
        "import cv2 as cv21#OpenCV\n",
        "from os import listdir\n",
        "import time\n",
        "import threading"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kJ045LFNlMq6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "facecascade = cv2.CascadeClassifier('e:/haarcascade_frontalface_default.xml')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ulsHLxv-2QCR",
        "colab_type": "code",
        "outputId": "869ec218-26af-4446-fb74-95daf918df0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "#put your employee pictures in this path as name_of_employee.jpg\n",
        "employee_pictures = \"e:/employeephotos/\"\n",
        "\n",
        "known_face_encodings =[]\n",
        "known_face_names =[]\n",
        "\n",
        "for file in listdir(employee_pictures):\n",
        "    employee, extension = file.split(\".\")\n",
        "    img = face_recognition.load_image_file('e:/employeephotos/%s.jpg' % (employee))\n",
        "    face_location = face_recognition.face_locations(img ,number_of_times_to_upsample=0, model=\"cnn\")\n",
        "    img_encoding = face_recognition.face_encodings(img)[0]\n",
        "    known_face_encodings.append(img_encoding)\n",
        "    known_face_names.append(employee)\n",
        "\n",
        "\n",
        "print('employee representations retrieved successfully')      "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "employee representations retrieved successfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N-FZYHv4QV9B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "class VideoCaptureAsync:\n",
        "    def __init__(self, src=0, width=640, height=480):\n",
        "        self.src = src\n",
        "        self.cap = cv2.VideoCapture(self.src)\n",
        "        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
        "        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
        "        self.grabbed, self.frame = self.cap.read()\n",
        "        self.started = False\n",
        "        self.read_lock = threading.Lock()\n",
        "\n",
        "    def set(self, var1, var2):\n",
        "        self.cap.set(var1, var2)\n",
        "\n",
        "    def start(self):\n",
        "        if self.started:\n",
        "            print('[!] Asynchroneous video capturing has already been started.')\n",
        "            return None\n",
        "        self.started = True\n",
        "        self.thread = threading.Thread(target=self.update, args=())\n",
        "        self.thread.start()\n",
        "        return self\n",
        "\n",
        "    def update(self):\n",
        "        while self.started:\n",
        "            grabbed, frame = self.cap.read()\n",
        "            with self.read_lock:\n",
        "                self.grabbed = grabbed\n",
        "                self.frame = frame\n",
        "\n",
        "    def read(self):\n",
        "        with self.read_lock:\n",
        "            frame = self.frame.copy()\n",
        "            grabbed = self.grabbed\n",
        "        return grabbed, frame\n",
        "\n",
        "    def stop(self):\n",
        "        self.started = False\n",
        "        self.thread.join()\n",
        "        self.cap.release()\n",
        "\n",
        "    def __exit__(self, exec_type, exc_value, traceback):\n",
        "        self.cap.release()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ib09M2diiJNt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rescale_frame(frame, percent=75):\n",
        "      width = int(frame.shape[1] * percent/ 100)\n",
        "      height = int(frame.shape[0] * percent/ 100)\n",
        "      dim = (width, height)\n",
        "      return cv2.resize(frame, dim, interpolation =cv2.INTER_AREA) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HnTkqP5_Ahov",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import requests \n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "# Initialize some variables\n",
        "face_locations = []\n",
        "face_encodings = []\n",
        "face_names = []\n",
        "process_this_frame = True\n",
        "#video_capture = cv2.VideoCapture(0)\n",
        "video_capture = VideoCaptureAsync(0)\n",
        "video_capture.start()\n",
        "while True:\n",
        "    # Grab a single frame of video\n",
        "    ret, frame = video_capture.read()\n",
        "    #frame = rescale_frame(frame,50)\n",
        "      \n",
        "    # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
        "    rgb_frame = frame[:, :, ::-1]\n",
        "    \n",
        "    \n",
        "    # Find all the faces and face enqcodings in the frame of video\n",
        "    face_locations = face_recognition.face_locations(rgb_frame ,number_of_times_to_upsample=0, model=\"cnn\")\n",
        "    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
        "\n",
        "    # Loop through each face in this frame of video\n",
        "    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
        "        # See if the face is a match for the known face(s)\n",
        "        matches = face_recognition.compare_faces(known_face_encodings, face_encoding,0.45)\n",
        "\n",
        "        name = \"Unknown\"\n",
        "\n",
        "        # If a match was found in known_face_encodings, just use the first one.\n",
        "        if True in matches:\n",
        "            first_match_index = matches.index(True)\n",
        "            name = known_face_names[first_match_index]\n",
        "           \n",
        "\n",
        "            \n",
        "        # Draw a box around the face\n",
        "        cv21.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
        "\n",
        "        # Draw a label with a name below the face\n",
        "        cv21.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
        "        font = cv21.FONT_HERSHEY_DUPLEX\n",
        "        cv21.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
        "\n",
        "    # Display the resulting image\n",
        "    cv21.imshow('Video', frame)\n",
        "\n",
        "    # Hit 'q' on the keyboard to quit!\n",
        "    if cv21.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release handle to the webcam\n",
        "#video_capture.release()\n",
        "video_capture.stop()\n",
        "cv21.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}